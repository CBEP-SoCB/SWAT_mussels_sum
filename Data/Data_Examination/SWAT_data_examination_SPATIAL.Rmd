---
title: "Review of Maine DEP EGAD Mussel Tissue Toxics Spatial Data"
subtitle: "Analysis of Sites and Sampling Points"
author: "Curtis C. Bohlen, Casco Bay Estuary Partnership"
date: "9/10/2020"
output:
  github_document:
    toc: true
    toc_depth: 2
    fig_width: 7
    fig_height: 5
---

<img
  src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
  style="position:absolute;top:10px;right:50px;" />

# Introduction
Maine's Department of Environmental Protection (DEP) maintains a large database
of environmental data called "EGAD".  Citizens can request data from the
database through DEP staff.

CBEP requested data from DEP on levels of toxic contaminants in shellfish
tissue samples from Casco Bay. The result is a large (> 100,000 line) excel
spreadsheet containing data from about 40 sampling dates from 20 locations, over
a period of more than 15 years.

Unfortunately, the data delivery contains little metadata, so it takes some
effort to understand the data format and analyze it correctly. Among other
problems, we need to understand dates and locations of samples, what analytes
were used for different samples, etc.

In this notebook and accompanying notebooks, we take various slices through the
data to understand its structure.

This Notebook generates the following derived data files:

sample_spatial.csv
sites_spatial.csv


# Load Libraries
```{r load_libraries}
library(tidyverse)
library(readxl)
library(htmltools)  # used by knitr called here only to avoid startup text later in document
library(knitr)

library(CBEPgraphics)
load_cbep_fonts()
theme_set

library(LCensMeans)
```
# Load Data
## Establish Folder Reference
```{r folder_refs}
auntfldnm <- 'Original_Data'
parent   <- dirname(getwd())
grandparent <- dirname(parent)
aunt  <- file.path(grandparent,auntfldnm)
fn <- 'CascoBaySWATtissue_Bohlen.xlsx'
```

## Copy Data
This is a larger data file that takes some time to load.  Getting the column
types right dramatically improves load speed. Much of the data is qualitative,
and can't be handled in R.
```{r copy_data}
SWAT_data <- read_excel(file.path(aunt, fn), 
    sheet = "Mussels Data", col_types = c("numeric", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "date", "text", "text", 
        "text", "date", "text", "numeric", 
        "text", "text", "text", "text", 
        "text", "numeric", "numeric", "text", 
        "text", "text", "text", "text", 
        "text", "numeric", "text", 
        "text", "text", "text", "text", 
        "text", "text", "text"))

before <- nrow(SWAT_data)
```

## Remove duplicates
Many samples -- nearly 20% -- are members of a group of duplicates.  We can
think of no valid reason why two records should be exact duplicates in this
setting, so we remove all duplicates using the unique() function.

```{r}
SWAT_data <- unique(SWAT_data)
```

# Sites
## List of Sites
Note that we pull apart the site name into a site code and a longer name.
```{r}
sites <- SWAT_data %>%
  select(`SITE SEQ`, `EGAD_SITE_NAME`) %>%
  group_by(`SITE SEQ`, `EGAD_SITE_NAME`) %>%
  summarize(SiteCode =  first(sub('.* - ','', `EGAD_SITE_NAME`)), 
            Site =  first(sub(' - .*','', `EGAD_SITE_NAME`)),
                        .groups = 'drop') %>%
  select(-`EGAD_SITE_NAME`)
#write_csv(sites, 'cb_SWAT_sites_list.csv')
kable(sites)
```

We can check that the results are unique:
```{r}
any(duplicated(sites$`SITE SEQ`))
any(duplicated(sites$SiteCode))
any(duplicated(sites$Site))
```

## Match Sites with Geographic Locations
In addition to the toxics data, we received a separate Excel file containing
geospatial data.  That data includes repeat geographic data for each site,
apparently providing more information on separate sample collection events.

As far as we have been able to tell, however, there is no single consistent
sample identifier between the geographic data and toxics data as received.

It appears we can match sites from the geospatial data based
on`SITE SEQ` or by pulling apart the "EGAD_SITE_NAME" and "CURRENT_SITE_NAME"
into a name and a code, and matching by code.

Sample locations are more complicated, sincee in many cases, the same string
is used to designate replicates at different SITEs.  That is, sample points
are not unique, athough the combination of sample point,  site and year does 
appear to be unique.

Here we reduce the spatial data to data on each nominal sampling location, and
check that we have geographic data for each site.  As is often the case, we lack
precise metadata on geographic coordinates. We do know locations were collected
in most cases with hand-held GPS units, which suggests lat-long data are
probably in WGS 1984.

We will need to return to the spatial data later to see whether sampling events
have slightly different nominal sampling locations from their reported sites.

```{r}
fn <- 'CascoBay_SWAT_Spatial.xlsx'
samples_spatial_data <- read_excel(file.path(aunt, fn))%>%
  mutate(`SITE UTM X` = as.numeric(`SITE UTM X`),
         `SITE UTM Y` = as.numeric(`SITE UTM Y`),
         `SITE LATITUDE` = as.numeric(`SITE LATITUDE`),
         `SITE LONGITUDE` = as.numeric(`SITE LONGITUDE`),
         `SAMPLE POINT UTM X` = as.numeric(`SAMPLE POINT UTM X`),
         `SAMPLE POINT UTM Y` = as.numeric(`SAMPLE POINT UTM Y`),
         `SAMPLE POINT LATITUDE` = as.numeric(`SAMPLE POINT LATITUDE`),
         `SAMPLE POINT LONGITUDE` = as.numeric(`SAMPLE POINT LONGITUDE`),
  )

sites_spatial_data <- samples_spatial_data  %>%
  rename(SITESEQ = `SITE SEQ`) %>%
    group_by(SITESEQ) %>%
    summarize(SITECODE  = first(sites$SiteCode[match(SITESEQ, sites$`SITE SEQ`)]),
              SITE  = first(sites$Site[match(SITESEQ, sites$`SITE SEQ`)]),
              UTM_E = first(`SITE UTM X`),
              UTM_N = first(`SITE UTM Y`),
              LAT   = first(`SITE LATITUDE`),
              LONG  = first(`SITE LONGITUDE`),
              .groups = 'drop') 
kable(sites_spatial_data)
#rm(sites)
```

```{r}
sum(! is.na(sites_spatial_data$SITE))
```
So, all DEP mussel tissue SITEs are included. Presumably the other sites have
samples of other shellfish (clams, in particular were provided in the second tab
of the source Excel File).


# Sample Points
Many Sites have more than one SAMPLE POINT.  The SAMPLE POINTs appear
to be the real sampling locations, each associated with a nominal SITE.
Unfortunately, recording of actual sampling locations may have been inconsistent
with real SAMPLE POINT data not always available, especially from some earlier
sample years.

## Examine Distances between Site and Sample Points
```{r}
a <- samples_spatial_data %>%
  select(`SITE SEQ`, CURRENT_SITE_NAME, `SITE UTM X`, `SITE UTM Y`,
         `SAMPLE POINT NAME`, `SAMPLE POINT SEQ`,
         `SAMPLE POINT UTM X`,`SAMPLE POINT UTM Y`) %>%
  mutate(SiteCode =  sub('.* - ','', `CURRENT_SITE_NAME`)) %>%
  mutate(d = sqrt((`SAMPLE POINT UTM X` -`SITE UTM X`)^2 + 
                  (`SAMPLE POINT UTM Y` -`SITE UTM Y`)^2)) %>%
  group_by(`SiteCode`) %>%
  summarize(sitex    = first(`SITE UTM X`),
            sitey    = first(`SITE UTM Y`),
            maxx    = round(max(abs(`SAMPLE POINT UTM X` - `SITE UTM X`)),2),
            maxy    = round(max(abs(`SAMPLE POINT UTM Y` - `SITE UTM Y`)),2),
            maxd    = round(max(d), 2),
            n = n(),
            .groups = 'drop') %>%
  select(-sitex, -sitey)
kable(a, col.names = c('Site', 'Max X Distance', 'Max Y Distance', 'Maximum Distance From Site', 'N'))
rm(a)
```

Several  Sites show (unreasonable?) large differences between Sample Points
and nominal Site locations.  To make sense of this, we mapped Sites and 
Sample Points in Arc GIS.

## Map Visualization
![Map of SWAT Sampling Locations and Nominal Sites](SWAT_Toxics_Locations.jpg)
The map shows clearly that sites represent general areas, not the exact
locations where samples were collected. In most cases, the distances are trivial
on a map of this scale, but not always.

*  **CBBBBB -- Back Bay**:  Do not appear to be typos, but exact locations do
   not appear to have been collected in all years.  Samples appea rto have been
   collected from various locations along the Back Bay Shoreline. identical for
   all samples.  Locations in Samples in 2015 all fairly consistent, but differ
   slightly.
*  **CBHWNP -- Harpswell Navy Pier**:  Multiple samples from each of two years,
   were given identical GPS coordinates.  The two locations are some distance
   apart.  
*  **CBMBBR  -- Brunswick Mare Brook**:  States positions from 2015 only
   accurate to 1000m. but they look better. Sampling Points are spread out along
   the shoreline and the nominal Site location is not all that close to most of
   them, but is located bayward of them.
*  **CBPRES -- Presumpscot River East** -- Sample Points along shore, East shore.  
*  **CBPRWS -- Presumpscot River West** -- Sample Points along shore, West shore.  
*  **CBPRM  -- Presumpscot River Mouth** -- Sample Points along shore, BOTH shores.  

## Missing Sample Point Data
Some Sites do not appear to have independent location data for sample points, or
not for all sample points.  That is actually easier to see in the Excel file,
but we can look at it in R by searching for NAs.
```{r}
samples_spatial_data %>%
  filter(is.na(`SAMPLE POINT UTM X`)) %>%
  select(-starts_with('SITE'), - starts_with('LOCATION'))
```

This affects the followingfive sites atleast once:
```{r}
samples_spatial_data %>%
  filter(is.na(`SAMPLE POINT UTM X`)) %>%
  select(CURRENT_SITE_NAME) %>%
  unique()
```

In several cases, this represents missing data from just one year, for
sites that were sampled repeatedly. Unfortunately, a quick review of the
data shows that similar sample point names (for replicates) were used for
different physical locations, with UTM coordinates suggesting samples with 
similar names in different years were often collected well over 100 meters
apart.  We can not readily "rescue" missing data based on data from prior years.

Accordingly, it appears that the best we can do is assign data to Sites, even
though samples for some sites are spread over hundreds of meters of shoreline.

## Write CSV file for GIS
First, we discard site data for locations for which we have no mussel samples.
Since we used names sites to generate the SITE code, we can check if that
is NA.  If it is, we have no related mussel samples.
```{r}
sites_spatial_data <- sites_spatial_data %>%
  filter(! is.na(SITECODE))

#write_csv(sites_spatial_data, 'sites_spatial.csv')
```

ArcGIS was having trouble reading earlier drafts of the following file, so we
simplify here by removing spaces from column names and removing NAs.
Without this step, NAs were forcing ArcGIS to interpret data columns as
text.
```{r} 
samples_spatial_data %>%
  select ( -`SITE UTM X`, -`SITE UTM Y`, -`SITE LATITUDE`, -`SITE LONGITUDE`,
           - DATA_SOURCE, -LOCATION_ACCURACY, -LOCATION_METHOD) %>%
  rename_all(~gsub(' ', '', .))
#write_csv('samples_spatial.csv', na = '')
```

