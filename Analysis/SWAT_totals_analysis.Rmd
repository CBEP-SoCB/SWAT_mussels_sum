---
title: "Analysis of Organic COntaminant Totals from EGAD Mussel Toxics Data"
author: "Curtis C. Bohlen, Casco Bay Estuary Partnership"
date: "11/02/2020"
output:
  github_document:
    toc: true
    toc_depth: 2
    fig_width: 7
    fig_height: 5
---

<img
  src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
  style="position:absolute;top:10px;right:50px;" />

# Introduction
Maine's Department of Environmental Protection (DEP) maintains a large database
of environmental data called "EGAD".  Citizens can request data from the
database through DEP staff.

CBEP requested data from DEP on levels of toxic contaminants in shellfish
tissue samples from Casco Bay. The result is a large (> 100,000 line) excel
spreadsheet containing data from about 40 sampling dates from 20 locations, over
a period of more than 15 years.

In this Notebook, we analyze organic contaminants found in blue mussel (*Mytilus
edulis*) tissue.  To simplify presentation of levels of organic contaminats, we 
focus here on various sums or related organic contaminants that can be related
more readily to other totals, in reference sources or other media.

We focus on the following analytic totals:

* Total PAHs, 
* Total PCBs,
* "SWAT PCBs"
* Total Dioxins, 
* Total DDT Residues

# Load Libraries
```{r load_libraries}
library(tidyverse)
library(readxl)
library(htmltools)  # used by knitr called here only to avoid startup text later in document
library(knitr)

library(mblm)
library(emmeans)

library(CBEPgraphics)
load_cbep_fonts()
theme_set(theme_cbep())

library(LCensMeans)
```

# Load Data
## Establish Folder Reference
```{r folder_refs}
sibfldnm <- 'Derived_Data'
parent   <- dirname(getwd())
sibling  <- file.path(parent,sibfldnm)
fn <- 'SWAT_totals_working.csv'
```

## Copy Data
This is a larger data file that takes some time to load.  Getting the column
types right dramatically improves load speed. Much of the data is qualitative,
and can't be handled in R, so we delete it.

To save on keystrokes, we also clean up the parameter names.
```{r}
swat_totals <- read_csv(file.path(sibling, fn),
                        col_type = cols(
                          .default = col_character(),
                          site_seq = col_double(),
                          year = col_integer(),
                          sample_date = col_date(format = ""),
                          concentration = col_double(),
                          lab_qualifier = col_logical(),
                          dilution_factor = col_double(),
                          conc_ugg = col_double(),
                          conc_ngg = col_double(),
                          rl_ugg = col_skip(),
                          rl_ngg = col_skip()
                        )) %>%
  select(-site_seq, -lab, -method, -method_name,
         -prep_method, -dilution_factor, -cas_no) %>%

  mutate(parameter = sub('-H', '', parameter)) %>%
  mutate(parameter = sub(' \\(ND=1/2 DL\\)', '', parameter)) %>%
  mutate(parameter = sub('TOTAL ', '', parameter)) %>%
  mutate(parameter = tolower(parameter)) %>%
  mutate(parameter = sub(' ', '_', parameter))
```


```{r}
unique(swat_totals$parameter)
```

## Load Reference Values
There is no good way to establish toxicity benchmarks for edible tissue.  Maine
DEP instead compares values of analytic totals to prevalence benchmarks (medians
and 85th percentiles) derived from the Gulfwatch and National Status And trends
monitoring programs, as published by Leblanc et al. 2009.

> Leblanc, L.A., Krahforst, C.F., Aub√©, J., Roach, S., Brun, G., Harding, G.,
  Hennigar, P., Page, D., Jones, S., Shaw, S., Stahlnecker, J., Schwartz, J.,
  Taylor, D., Thorpe, B., & Wells, P. (2009).  Eighteenth Year of the Gulf of
  Maine Environmental Monitoring Program.

We copied benchmark tables from (an on-line version of) Leblanc et al. 2009 into
our excel spreadsheet, and read those benchmarks in here.

```{r}
references <- read_excel(file.path(sibling,"Parameter List.xlsx"), 
                             sheet = "Organic Comparisons",
                         range = 'a3:f8') %>%
  rename('Reference_ngg' = ...1) %>%
  filter(! is.na(Reference_ngg)) %>%
  mutate(Reference_ngg = sub(' 2008', '', Reference_ngg))
```

## Load Location Information
And add a short location name for figures.
```{r}
locations <- read_csv(file.path(sibling,"sites_spatial.csv"), 
    col_types = cols(SITESEQ = col_skip(), 
        LAT = col_skip(), LONG = col_skip())) %>%

  mutate(short_locs= c("Back Bay",
                      "Fore River",
                      "Cocktail Cove",
                      "SW Great Diamond",
                      "Navy Pier",
                      "Mill Creek",
                      "Royal River",
                      "Haraseeket",
                      "Falmouth",
                      "Mare Brook",
                      "Fore River",
                      "East End",
                      "Spring Point",
                      "Jewel Island",
                      "Presumpscot",
                      "Middle Bay",
                      "Maquoit Bay",
                      "Inner Fore",
                      "Quahog Bay",
                      "Long Island"))
```

### Add Short Location Names
Adding short location names  and creating a lookup table to facilitate later
graphics.  These are probably not both necessary.
```{r}
swat_totals <- swat_totals %>%
  mutate(short_locs = locations$short_locs[match(sitecode, locations$SITECODE)])


label_lookup <- swat_totals %>%
  select(sitecode, concentration)%>%
  mutate(sc = fct_reorder(sitecode, concentration)) %>%
  mutate(short_locs = locations$short_locs[match(sc, locations$SITECODE)]) %>%
  select(-concentration, -sitecode) %>%
  unique()
```

# Functions to add Reference Annotations
By isolating the code for adding annotations, we can redesign the annotations 
once, and have it percolate through all graphics.  This could be
generalized by adding dots... to pass through to the underlying functions.

## Utilities to Extract Axis Ranges
These functions do not yet properly account for multiple plots due to faceting.
```{r}
get_xrange <- function(p) {
  ggp <- ggplot_build(p)
  return(ggp$layout$panel_params[[1]]$x.range)
}
  
get_yrange <- function(p) {
  ggp <- ggplot_build(p)
  return(ggp$layout$panel_params[[1]]$y.range)
}
```


The following code positions annotations at 2.5% of the x range from the left
edge. That positioning could be relegate to a parameter.  This function could
be generalized by handling dots, but it's not clear whether the dots should
be directed to the lines or to the text annotations.
```{r}
add_refs <- function(plt, parm = 'PAH40', whch = c(1:4), sz = 3) {
  plt2 <- plt
  # Extract x range and calculate annotation position
  xrng <- get_xrange(plt2)
  xpos <- xrng[1] + 0.025*(xrng[2]-xrng[1])
  
  # Draw the Reference Lines
  for (refline in (1:4)) {
      if (refline %in% whch){
        plt2 <- plt2 + 
        geom_hline(yintercept = references[[parm]][refline],
                   color = cbep_colors2()[1],
                   lwd = 0.5, lty = 2)
      }
  }
  
  # Draw the Associated Text Annotations
  labs = references[whch,]
  plt2 <- plt2 + 
  geom_text(data = labs,
            aes(x = xpos, y = .data[[parm]], label = Reference_ngg),
            hjust = 0,
            size = sz,
            nudge_y = .03)
      
  return(plt2)
  }
```



# Cross Tab to Look at Sample Distributions
```{r}
xtabs(~ sitecode + year , data = swat_totals,
      subset = parameter == 'pah19')
```
We have few sites with good temporal coverage.  Most sites were only sampled
once. The high frequency sites (three or more sample years) include:
*  CBEEEE   -- 
*  CBMCMC
*  CBSPSP

In addition, CBMBBH was sampled twice.  Other sites were each sampled only once,
making them problematic for trend analysis, since sites are NOT random samples
drawn from a well defined population of sites.

We have only two years, and three sites (our three high frequency sites) sampled
since our last State of the Bay report, to offer a recent "status" update.  If
we extend to the last ten years, we only pick up only two more, both sampled in
2014.

Certain years, notably 2007 and 2009 have relatively dense spatial coverage,
however, 2007 lacks some categories of data or diagnostic totals.

```{r}
xtabs(~ parameter + year , data = swat_totals)
```
So, we have dioxin data ONLY from 2008, and pesticides data no more recently
than 2012.  That makes both problematic for trend analysis, and both too old for
a current "status" update.

The core of this analysis therefore will be on PAHs and PCBs.

#  PAHs
## Data since 2010
Recent data can be summarized with more complete totals -- the PAH 40 is
availalbe for the entire period.

Give the paucity of data and sited from 2015 through 2019, we consider "recent"
data to include the lat 10 years, or 2010 throut 2019
```{r}
pah_data <- swat_totals %>%
  filter(grepl('pah', parameter))

pah_recent_data <- pah_data %>%
  filter(year >= 2010)
```

```{r}

plt <- ggplot(pah_recent_data,
              aes(fct_reorder(short_locs, conc_ngg), conc_ngg)) +
  geom_point(aes(color = parameter)) +
  scale_y_log10() +
  theme_cbep(base_size = 12) +
  ylab("Concentration (ng/g)") +
  xlab('Location')
plt
```
So, rank order of sites is fairly consistent.  PAH 19 is a fraction of Total
PAHs, but rank order is similar.  PAH 40 appears pretty consistently similar to
total PAHs, something close to 80% of the larger sum.

```{r}
swat_totals %>%
  filter(parameter == 'pah40' | parameter == 'pah') %>%
  filter(year > 2009) %>%
  group_by(sitecode, year) %>%
  summarize(n_total = sum(parameter =='pah'),
            sum_total = sum((parameter =='pah') * concentration),
            mean_total = sum_total/n_total,
            n_40 = sum(parameter =='pah40'),
            sum_40 = sum((parameter =='pah40') * concentration),
            mean_40 = sum_40/n_40,
            ratio = mean_40 / mean_total) %>%
  select(-n_total, -sum_total, -n_40, -sum_40) %>%
  pull(ratio) %>%
  mean()
```
```{r}
pah_data %>%
  select(code, lab_id, parameter, conc_ngg) %>%
  pivot_wider(names_from = parameter, values_from = conc_ngg) %>%
  select(-code, -lab_id) %>%
  cor(use='pairwise')
```
What that shows is all these PAH values are highly correlated.  The more limited
lists (pah19 and pah24) are closely correlated with each other.  PAH40 and total
PAHs are highly correlated.

### PAH 40
So, we focus on PAH 40, since it matches a benchmark, and approximates total
PAHs fairly well.  Our primary interest in the status analysis is to compare
observations to benchmarks. We do this principally graphically.

#### Jittered Graphic
```{r}
plt <- pah_recent_data %>%
  filter(parameter == 'pah40') %>%
  ggplot(aes(fct_reorder(short_locs, conc_ngg), conc_ngg)) +
  geom_jitter(mapping = aes(fill = as.integer(year)),
             size = 3,
             shape = 21,
             width = 0.05) +
  scale_fill_gradient(name = 'Year',
                        low = cbep_colors2()[1],
                        high = cbep_colors2()[4]) +
  scale_y_log10() +
  theme_cbep(base_size = 12)  +
  ylab('Concentration (ng/g)') +
  xlab('Location')
```

```{r}
add_refs(plt, parm = 'PAH40', whch = c(2,4))
```


#### Means and Two Standard Errors
```{r}
plt <- pah_recent_data %>%
  filter(parameter == 'pah40') %>%
  group_by(short_locs) %>%
  summarize(avg = mean(conc_ngg, na.rm = TRUE),
           std_dev = sd(conc_ngg, na.rm = TRUE),
           n = sum(! is.na(conc_ngg)),
           std_err = std_dev/sqrt(n),
           .groups = 'drop') %>%
  

  ggplot(aes(fct_reorder(short_locs, avg), avg)) +
  geom_errorbar(aes(ymin = avg-2 * std_err, ymax = avg + 2 * std_err),
                width = .15) +
  geom_point(color = cbep_colors()[1],
             size = 5) +
  
  scale_y_log10() +
  theme_cbep(base_size = 12)  +
  ylab('Concentration (ng/g)') +
  xlab('Location') +
  ggtitle("Don't Use! Potentially misleading.")

add_refs(plt, parm = 'PAH40', whch = c(2,4))

```
#### Log Linear Model Marginal Means and Confidence Intervals Explore Linear Model Among Sites
A better approach is to explicitly model this as a log linear model and extract
expectations and confidence intervals from the model object, using emmeans.

```{r}
sites_lm <- lm(log(conc_ngg) ~ short_locs, data = pah_recent_data)
anova(sites_lm)
oldpar <- par(mfrow = c(2,2))
plot(sites_lm)
par(oldpar)
```
That q-q plot is abysmal!  The other model diagnostics are fine. Untransformed 
shows marked scale-dependence of variability, which is largely missing here.
We'd be far better off wit ha model that better fit the random component of
these data.

```{r}
emm <- emmeans(sites_lm, "short_locs", type = 'response')
(sm <- summary(emm, adjust = "tukey"))
```
```{r}
plt <- sm %>% arrange(response) %>%
  ggplot(aes(x = fct_reorder(short_locs, response), y = response)) +
  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL),
                width = .15) +
  geom_point(color = cbep_colors()[1],
             size = 5) +
  
  scale_y_log10() +
  theme_cbep(base_size = 12)  +
  ylab('Concentration (ng/g)') +
  xlab('Location')
```

```{r}
add_refs(plt, parm = 'PAH40', whch = c(2,4))
```

That is more appropriate, but rests on a shaky modeling foundation, and may
itself be misleading.  In particular, the error bars for the smaller means 
are effectively "infected" with the high variability of the larger means. Despite
no variability to speak of at Navy Pier, we get significant standard errors
because variability is estimated based on all sites. 

#### Dot Histogram
```{r}
plt <- pah_recent_data %>%
  filter(parameter == 'pah40') %>%
  
  ggplot(aes(fct_reorder(short_locs, conc_ngg), conc_ngg)) +
 
  geom_dotplot(method = 'histodot',
               binaxis='y',
               stackdir='center',
               binpositions="all",
               fill = cbep_colors()[1]
               ) +
  
  scale_fill_gradient(name = 'Year',
                        low = cbep_colors2()[1],
                        high = cbep_colors2()[4]) +
  scale_y_log10() +
  theme_cbep(base_size = 14)  +
  ylab('Sum of 40 PAHs (ng/g)') +
  xlab('')
```

```{r}
add_refs(plt, parm = 'PAH40', whch = c(2,4), sz = 3)
```

# Trend Site Analyses
```{r}
sites <- c('CBEEEE', 'CBMCMC', 'CBSPSP')
pah_trend_data <- swat_totals %>%
  filter(grepl('pah', parameter)) %>%
  filter(sitecode %in% sites)
```

## PAH-40 Graphic
```{r}
plt <- pah_trend_data %>%
  filter(parameter == 'pah40') %>%
  
  ggplot(aes(year, conc_ngg)) +
  geom_point(aes(color = short_locs), size = 3, alpha = .5) +
  
  geom_smooth(aes(color = short_locs), method = 'lm', se = FALSE) +
  scale_y_log10() +
  
  theme_cbep(base_size = 12)  +
  theme(legend.title = element_blank()) +
  scale_color_manual(values = cbep_colors()) +
  scale_x_continuous(labels = scales::label_number(accuracy = 1)) +
  
  ylab('Sum of 40 PAHs (ng/g)') +
  xlab('Year')
```

```{r}
add_refs(plt, parm = 'PAH40', whch = c(2,4))
```

THat is actually fairly remarkable, and suggests an ANCOVA.  Lets also look at
PAH-19, which gives a slightly longer time period.

## PAH-40 linear models
We select an optimal model using AIC criteria.
```{r}
full_pah40_lm <- lm(log(conc_ngg) ~ sitecode * year, data = pah_trend_data,
                    subset = parameter == 'pah40')
pah40_lm <- step(full_pah40_lm)
```

```{r}
summary(pah40_lm)
```
What that shows is little or no difference in slopes, but a meaningful
difference in base levels.  
*  Since this is a log regression, the slope is close to annual percent
   reduction, so concentration of these PAHs has dropped on average about 8% a
   year over the past decade or so.
*  The Mill Creek Samples are a factor of just under three (exp(1)) smaller
   that the other two sites.

## PCBs
```{r}
pcb_data <- swat_totals %>%
  filter(grepl('pcb', parameter))

pcb_recent_data <- pcb_data %>%
  filter(year > 2009)

pcb_trend_data <- pcb_data %>%
  filter(! grepl('teq', parameter)) %>%
  filter(sitecode %in% sites)
```

### Preliminary Graphic
```{r}
plt <- ggplot(pcb_recent_data, aes(fct_reorder(sitecode, conc_ngg), conc_ngg)) +
  geom_point(aes(color = parameter), alpha = 0.5) +
  scale_y_log10() +
  theme_cbep(base_size = 12)
plt
```
SWAT PCBs are slightly smaller than Total PCBs.  It makes little sense that TEQs
are so much lower.  I wonder if these are in fact reported in different units.  
They are reported as being in pg/g, as are the other PCB values but the values
are several orders of magnitude lower, which makes little sense.   different units

### Correlations
```{r}
pcb_data %>%
  select(code, lab_id, parameter, conc_ngg) %>%
  pivot_wider(names_from = parameter, values_from = conc_ngg) %>%
  select(-code, -lab_id) %>%
  cor(use='pairwise')
```
So even though SWAT PCBs are order are highly correlated, but the TEQs are only
moderately correlated with the other two measures.
We conclude we should be comparing the

###  Barchart 
```{r}
plt <- pcb_recent_data %>%
  filter(! parameter == 'pcb_teq') %>%
  select(short_locs, sample_id, conc_ngg, year, parameter) %>%
  group_by(short_locs, parameter) %>%
  summarize(val = mean(conc_ngg),
            std_dev = sd(conc_ngg, na.rm = TRUE),
            n = sum(! is.na(conc_ngg)),
            std_err = std_dev/sqrt(n),
           .groups = 'drop') %>%
  
  ggplot(aes(fct_reorder(short_locs, val), val, fill = parameter)) +
    scale_fill_manual(values = cbep_colors(),
                      labels = c('Total PCBs', 'SWAT PCBs'),
                      name = '', )  +
    geom_col(position = position_dodge()) +
    geom_errorbar(aes(ymin = val - 2 * std_err,
                  ymax = val + 2 * std_err), 
                  width = 0.2,
                  position = position_dodge(0.9)) +
  ylab("Concentration (ng/g)") +
  xlab('') +
  theme_cbep(base_size = 14)
plt
```

#### Dot Histogram
```{r}
plt <- pcb_recent_data %>%
  filter(parameter == 'swat_pcbs') %>%
  
  ggplot(aes(fct_reorder(short_locs, conc_ngg), conc_ngg)) +
 
  geom_dotplot(method = 'histodot',
               binaxis='y',
               stackdir='center',
               binpositions="all",
               fill = cbep_colors()[5]
               ) +
  
  scale_fill_gradient(name = 'Year',
                        low = cbep_colors2()[1],
                        high = cbep_colors2()[4]) +
  scale_y_log10() +
  theme_cbep(base_size = 14)  +
  ylab('SWAT PCBs (ng/g)') +
  xlab('')
```

```{r}
add_refs(plt, parm = 'PCB21', whch = c(2,4), sz = 3)
```



## PCB Trends 
```{r}
sites <- c('CBEEEE', 'CBMCMC', 'CBSPSP')

plt <- pcb_trend_data %>%
  filter(parameter == 'swat_pcbs') %>%
  
  ggplot(aes(year, conc_ngg, color = short_locs)) +
  geom_point(size = 3, alpha = .5) +
  
  geom_smooth(method = 'lm', se = FALSE) +
  scale_y_log10() +
  
  theme_cbep(base_size = 12)  +
  theme(legend.title = element_blank()) +
  scale_color_manual(values = cbep_colors()) +
  scale_x_continuous(labels = scales::label_number(accuracy = 1)) +
  
  ylab('Sum of 40 PAHs (ng/g)') +
  xlab('Year')
plt
```

We select an optimal model using AIC criteria.
```{r}
full_swat_pcbs_lm <- lm(log(conc_ngg) ~ sitecode * year, data = pcb_trend_data,
                    subset = parameter == 'swat_pcbs')
swat_pcb_lm <- step(full_swat_pcbs_lm)
```

```{r}
summary(swat_pcb_lm)
```
So, the best model by AIC suggests no long-term trend,and no significant
interactions, although the graphic suggests a possible interaction, as 
concetratiosn at spring point appear to have been declining.  However, given
variability in observations, that could be due tochance.



